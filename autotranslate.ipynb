{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2048e6466b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "SEED = 2222\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vncorenlp import VnCoreNLP\n",
    "annotator = VnCoreNLP(\"VnCoreNLP-master\\VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Please', 'put', 'the', 'dustpan', 'in', 'the', 'broom', 'closet']\n",
      "['Cuốn', 'sách', 'này', 'là', 'của', 'tôi', '.', 'Của', 'bạn', 'đâu', '?']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import itertools\n",
    "\n",
    "def tokenize_en(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "def tokenize_vi(text):\n",
    "    return [tok for tok in itertools.chain.from_iterable(annotator.tokenize(text))]\n",
    "\n",
    "text_en = 'Please put the dustpan in the broom closet'\n",
    "text_vi = 'Cuốn sách này là của tôi. Của bạn đâu?'\n",
    "print(tokenize_en(text_en))\n",
    "print(tokenize_vi(text_vi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_raw_dataset():\n",
    "    data_dir = \"\"\n",
    "    en_sents = open(data_dir + 'english.txt', \"r\",encoding=\"utf-8\" ).read().splitlines()\n",
    "    vi_sents = open(data_dir + 'vietnamese.txt', \"r\" ,encoding=\"utf-8\").read().splitlines()\n",
    "    return {\n",
    "        \"English\": [line for line in en_sents[:5000]],\n",
    "        \"Vietnamese\": [line for line in vi_sents[:5000]],\n",
    "    }\n",
    "raw_data = create_raw_dataset()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.DataFrame(raw_data, columns=[\"English\", \"Vietnamese\"])\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.125)\n",
    "\n",
    "train.to_json(\"train.json\", orient=\"records\", lines=True)\n",
    "test.to_json(\"test.json\", orient=\"records\", lines=True)\n",
    "val.to_json(\"val.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 1535\n",
      "Unique tokens in target (vi) vocabulary: 1359\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "source_tokenizer = tokenize_en\n",
    "target_tokenizer = tokenize_vi\n",
    "\n",
    "def load_data(filename, source_tokenizer, target_tokenizer):\n",
    "    examples = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            src = source_tokenizer(example[\"English\"])\n",
    "            trg = target_tokenizer(example[\"Vietnamese\"])\n",
    "            examples.append((src, trg))\n",
    "    return examples\n",
    "\n",
    "train_examples = load_data(\"train.json\", source_tokenizer, target_tokenizer)\n",
    "val_examples = load_data(\"val.json\", source_tokenizer, target_tokenizer)\n",
    "test_examples = load_data(\"test.json\", source_tokenizer, target_tokenizer)\n",
    "\n",
    "def build_vocab(tokenized_sentences, max_size=None, min_freq=1):\n",
    "    word_counts = Counter(chain(*tokenized_sentences))\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "    if max_size is not None:\n",
    "        sorted_words = sorted_words[:max_size]\n",
    "    vocabulary = {\"<pad>\": 0, \"<unk>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
    "    for word, count in sorted_words:\n",
    "        if count >= min_freq and word not in vocabulary:\n",
    "            vocabulary[word] = len(vocabulary)\n",
    "    return vocabulary\n",
    "\n",
    "source_sentences_train = [example[0] for example in train_examples]\n",
    "target_sentences_train = [example[1] for example in train_examples]\n",
    "source_vocab = build_vocab(source_sentences_train, max_size=10000, min_freq=2)\n",
    "target_vocab = build_vocab(target_sentences_train, max_size=10000, min_freq=2)\n",
    "\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(source_vocab)}\")\n",
    "print(f\"Unique tokens in target (vi) vocabulary: {len(target_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Source sequences:\n",
      "tensor([148,  16,  10,   8,  74,  52,  70,   6,   0])\n",
      "tensor([[148,  16,  10,  ...,  70,   6,   0],\n",
      "        [  6,  56, 125,  ...,  34,   1,   0],\n",
      "        [  4,  47, 121,  ...,  46,   1,   0],\n",
      "        ...,\n",
      "        [  4,  66, 117,  ..., 122,  67,  18],\n",
      "        [  4,  33, 926,  ...,   1, 400, 203],\n",
      "        [  4,  69,  25,  ...,  98,  39, 801]])\n",
      "Target sequences:\n",
      "tensor([251,   6,   7,  37, 168,   8,  14,   0,   0,   0,   0,   0,   0])\n",
      "tensor([[251,   6,   7,  ...,   0,   0,   0],\n",
      "        [  8,  15, 121,  ...,   0,   0,   0],\n",
      "        [ 27,  17,   1,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  5,   9,  15,  ...,   0,   0,   0],\n",
      "        [ 27,   1, 128,  ...,   0,   0,   0],\n",
      "        [  5,  17,  99,  ...,   0,   0,   0]])\n",
      "Batch 1:\n",
      "Source sequences:\n",
      "tensor([ 6, 11, 12,  1,  1,  0])\n",
      "tensor([[  29,   47,   85,    8,  331,    0],\n",
      "        [   6,   11,   12,    1,    1,    0],\n",
      "        [   6,    1,   28,   14,  386,    0],\n",
      "        [  80,   11,    9,  535,    1,    0],\n",
      "        [  43,   51,    8,   49,    1,    0],\n",
      "        [   4,   33,  257,  130,  112,    0],\n",
      "        [  20,  344,  263,    7,  577,    0],\n",
      "        [   1,   11,   37,    7,  746,    0],\n",
      "        [ 140,    8,  456,   18,   31,    0],\n",
      "        [   6,  174,   66,   72,  513,    0],\n",
      "        [   6,   27,    4,   36,  361,    0],\n",
      "        [  81,   66,   62,    9,  180,    0],\n",
      "        [  29,   59,   12,    7,  431,    0],\n",
      "        [ 115,  363, 1375,    1,  187,    0],\n",
      "        [  43,    8,   48,    6,    1,    0],\n",
      "        [  24,  174,   25,   68,   83,    0],\n",
      "        [ 153,   14,   16,   23,  195,    0],\n",
      "        [ 568,   36,    6,   14,  239,    0],\n",
      "        [  35,   14,   26,    9,    1,    0],\n",
      "        [   6,   75,   10,  419,    8,    0],\n",
      "        [  55,  201,    5,   46,    1,    0],\n",
      "        [   6,  173,   37,   34,    1,    0],\n",
      "        [ 140,   87,   97,  124,    1,    0],\n",
      "        [1135,   95,   18,    7,    1,    0],\n",
      "        [  43,   65,   19,  271,  360,    0],\n",
      "        [ 218,    8,  298,   23,  110,    0],\n",
      "        [   6,   14,    1,  117,    1,    0],\n",
      "        [  81,   74,    1,  230,    1,    0],\n",
      "        [   4,  118,   23,   15,   83,    0],\n",
      "        [ 102,   11,    7,  615,  244,    0],\n",
      "        [   4,   62,    9, 1070,   58,    0],\n",
      "        [ 148,   15,   10,    4,    1,    0],\n",
      "        [ 919,   13,   95,   36,    1,    0],\n",
      "        [ 177,   78,   21,   46,    1,    0],\n",
      "        [   1,  550,  412,   11,    1,    0],\n",
      "        [  80,  688,   11,  109,  421,    0],\n",
      "        [ 391,  418,   27,  172, 1022,    0],\n",
      "        [   1,  106,   69,   26,   98,    0],\n",
      "        [ 113,    4,    1,    8,  170,    0],\n",
      "        [   6,  536,    7,    1,  226,    0],\n",
      "        [   4,   48,  114,  352,    6,    0],\n",
      "        [  20,  422,    9,  152,  269,    0],\n",
      "        [ 274,    8,  380,    1,  119,    0],\n",
      "        [ 689, 1184,    1,  156,    1,    0],\n",
      "        [   4,   15,  187,   45,    6,    0],\n",
      "        [ 115,   23,  876,  130,  112,    0],\n",
      "        [ 221, 1390,   56,  152, 1343,    0],\n",
      "        [ 938,   14,   12,  354,   57,    0],\n",
      "        [  29,   59,  420,   45,    8,    0],\n",
      "        [   4,   19,    9,    1,    1,    0],\n",
      "        [  55,   14,   46,  304,  846,    0],\n",
      "        [ 218,    8,   70,   32,    1,    0],\n",
      "        [   6,    1,  170,   34,    1,    0],\n",
      "        [  55,    1,   77,    6,  259,    0],\n",
      "        [  80,    1,   11,  176,    1,    0],\n",
      "        [   4,  149,    1,   18,    7,    1],\n",
      "        [  43,   10,    1,    6,   18,   17],\n",
      "        [ 541,   13,  379,   63,   26, 1250],\n",
      "        [  24,   86,  135,  172,   38,   21],\n",
      "        [  43,    8,   48,   44,    1,   11],\n",
      "        [   4,   62,   10,  118,   45,   17],\n",
      "        [  35,  265, 1491,   25,  454,  203],\n",
      "        [   4,    1,    7,    1,   38,  290],\n",
      "        [   4,   33,    1,    7,  138,  182],\n",
      "        [   4,   96,  192,    8,    5,   52],\n",
      "        [   6,  436,   12,    9, 1115,  685],\n",
      "        [  50,  157,   42,    9,  171,  864],\n",
      "        [   4,   62,    5,  418,   99, 1477],\n",
      "        [  55,   36,    8,  191,  184,   57],\n",
      "        [ 472,  502,   18,   42,   15,    1],\n",
      "        [   4,   33,  334,    5,   16,   23],\n",
      "        [   6,   14,   12,    9,    1, 1377],\n",
      "        [   4,    1,    5,    7,  978, 1330],\n",
      "        [   6,   56,   99,    5,   78,    8],\n",
      "        [   6,    1,   34,    1,  217,    1],\n",
      "        [   6,    1,    9, 1325,   13,  444],\n",
      "        [  22,  259,   15,    1,   73,   42],\n",
      "        [  29,   66,  117,  125,  624,  231],\n",
      "        [ 102,   75,    8,   48,   45,   17],\n",
      "        [   4,   33,   26,    1,   32,   58],\n",
      "        [  24,   91,   66,   96,   98,   57],\n",
      "        [   4,   19,    5,   52,   70,    6],\n",
      "        [ 150,  160,   11,  547,    7,  642],\n",
      "        [ 470,   36,    1, 1088,  194,    1],\n",
      "        [ 472,  359,   62,  385, 1339,    1],\n",
      "        [   1,   21,   38,   31,    1,    1],\n",
      "        [   6,  190,    4,   86,   25,   87],\n",
      "        [   6,   56,    7,    1,   28,  754],\n",
      "        [   1,   46,  662,   37,    7,    1],\n",
      "        [  35,   56,  886,   21,    1,    1],\n",
      "        [  20,   14,   62,  255,  215,    1],\n",
      "        [   6,  754,    5,  888,    7,    1],\n",
      "        [  22,  217,    1,    5,    7,    1],\n",
      "        [ 274,    8,   53,    5,  146,   99],\n",
      "        [1270,  130,   39,    7, 1080, 1037],\n",
      "        [ 177,   16,   10,  319,    7,    1],\n",
      "        [  29,  157,   82,    1,   18,    1],\n",
      "        [ 274,    8,  694,   46,  151,  380],\n",
      "        [  24,   16,   10,   70,    5,    1],\n",
      "        [   1, 1128,  368,   32, 1403,    1],\n",
      "        [  29,   63,    1,   12,    9,    1],\n",
      "        [ 148,   16,   10,    8,   16,  447],\n",
      "        [ 470,   11,    1,  952,  194,    1],\n",
      "        [   4,  319,   54,   67,  159,  127],\n",
      "        [  80,  174,   25,    7,  187,  482],\n",
      "        [   4,   64,   10,  645,   97,  371],\n",
      "        [  43,   10,    1,   67,    7, 1209],\n",
      "        [  24,   66,  310,    6,   14, 1406],\n",
      "        [  29,  993,    9,  386,   13,    1],\n",
      "        [   4,   33,  334,    8,  141,   17],\n",
      "        [   6,   77,   10,   48,    7,    1],\n",
      "        [ 103,  606,   27, 1192,   36,    1],\n",
      "        [  43,    8,   49,    6,  351,   28],\n",
      "        [  24,   64,   10,  172,   57,  248],\n",
      "        [   4,   16,   10,   19,    7,  623],\n",
      "        [  22,    1,   11,   26,  198,    1],\n",
      "        [   6,  118,   28,  883,  109,  247],\n",
      "        [  24,  329,   19,  143,   99,  749],\n",
      "        [  50,   11,   10,  272,    5,   42],\n",
      "        [   6,  356,    5,    1,   34, 1132],\n",
      "        [   6,   27,   28,  573,   82,    1],\n",
      "        [ 102,  129,   11,   17,   60,  261],\n",
      "        [  24,   59,  460,   18,  110,  129],\n",
      "        [  22,  171,    1,   11,  434,    1],\n",
      "        [ 952,   14,    1,   15,   68,    1],\n",
      "        [  20,   47,   25,   57,  130,  282],\n",
      "        [  29,   59,  216,    1,    1,    6],\n",
      "        [   4,   66,   96,   72,    1,  227]])\n",
      "Target sequences:\n",
      "tensor([  8,  12,  30,   1, 280,   1,   0,   0,   0,   0,   0])\n",
      "tensor([[ 64,  17,  78,  ...,   0,   0,   0],\n",
      "        [  8,  12,  30,  ...,   0,   0,   0],\n",
      "        [  8, 361, 334,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 13,  16,  17,  ...,   0,   0,   0],\n",
      "        [ 29,  34,  78,  ...,   4,   0,   0],\n",
      "        [  5,  89,  80,  ...,   0,   0,   0]])\n",
      "Batch 2:\n",
      "Source sequences:\n",
      "tensor([  4,  52,   5, 859, 159, 127,   0])\n",
      "tensor([[   4,   33,  299,   32,  464, 1522,    0],\n",
      "        [   4,   96,  275,   23,    9,  118,    0],\n",
      "        [   4,   52,    5,  859,  159,  127,    0],\n",
      "        [  81,   59,    1,    5,  291,  138,    0],\n",
      "        [ 113,    8,    1,   21,    9, 1080,    0],\n",
      "        [  29,   16,   10,  109,  108,    6,    0],\n",
      "        [   4,   96,  190,   34, 1059,  241,    0],\n",
      "        [   6,   77,   10,   53,  365,  450,    0],\n",
      "        [   1,    1,   27,    9,    1,  380,    0],\n",
      "        [ 115,   17,  295,    6,  194,    1,    0],\n",
      "        [  20, 1444,    1,   34,  613,    1,    0],\n",
      "        [   1,   27,    1,   36,   26,  239,    0],\n",
      "        [  35,   14,   74,    7,  130,    1,    0],\n",
      "        [  50, 1488,    5,    1,    7, 1359,    0],\n",
      "        [  35,  510,  998,    1,    1,  570,    0],\n",
      "        [ 148,   40,    8,  246,   53,   17,    0],\n",
      "        [  80,  447,   11,  332,   18,   21,    0],\n",
      "        [   6, 1385,   26,    5,   78,  321,    0],\n",
      "        [  20,   11,    1,    5,  807,  203,    0],\n",
      "        [  24,   59,   26,    1,    7,  317,    0],\n",
      "        [  35, 1432,    9,  132,  107,    1,    0],\n",
      "        [   4,  773,  225,  188,    5,    6,    0],\n",
      "        [   6,  548,   37,    7,    1,    1,    0],\n",
      "        [  29,  711,   52,   18,    9,  531,    0],\n",
      "        [   1,  795,  271,    5,   25,  228,    0],\n",
      "        [  20,   11, 1495,   39,    1,    1,    0],\n",
      "        [   6,  104,   21,    5,  401,   57,    0],\n",
      "        [   1,   36,    9, 1017, 1379,    1,    0],\n",
      "        [  55,   66,    8,   72,  184,    1,    0],\n",
      "        [   4,   64,   10,  493,   38,    6,    0],\n",
      "        [   6,  340,    5,  323,   28,   99,    0],\n",
      "        [   6,   77,  147,   65,   78,   42,    0],\n",
      "        [   4,   16,   26,   52,    5,  166,    0],\n",
      "        [ 148,   36,  204,  183,  198,    1,    0],\n",
      "        [ 113,    4,   19,    7,  944,  380,    0],\n",
      "        [   1, 1285,  231,  952,   18,   83,    0],\n",
      "        [   1,  109, 1350,  263,   54,  205,    0],\n",
      "        [ 153,   14,    1,    5,    7,  580,    0],\n",
      "        [  81,  275,   21,    9,   83,  611,    0],\n",
      "        [ 601,  333,  314,   61,  100,   95,    0],\n",
      "        [   6,    1,    1,   27,    1,    1,    0],\n",
      "        [  28,  442,    5,    1,   54,    1,    0],\n",
      "        [ 302,    7,  713,    1,    7,  240,    0],\n",
      "        [   1,    8,   18,    7,  279, 1143,    0],\n",
      "        [   4,   16,   10,   41,    9,  293,    0],\n",
      "        [   6,   27,    4,   19,  278,  817,    0],\n",
      "        [  22,    1,   15, 1053,   31,  307,    0],\n",
      "        [  22, 1409,   11,    1,    5,   21,    0],\n",
      "        [   4,   69,  158,    1,   39,  801,    0],\n",
      "        [  24,   91,   10,  158,  147,  670,    0],\n",
      "        [  20,   62, 1062,    9,  171, 1028,    0],\n",
      "        [ 103,  126,   56,  144,   76,  475,    0],\n",
      "        [  20,    1,    7,  542,   68,  134,    0],\n",
      "        [   4,  361,   32,  324,  166,    1,    0],\n",
      "        [  20,  322,   54,  159,  138,  127,    0],\n",
      "        [   4,  118,    8,  143,  207,  201,    0],\n",
      "        [  20,   11,  198,  235,   18,  166,    0],\n",
      "        [   6,    1,    5,  145,   38,   95,    0],\n",
      "        [   4,  118,    6,   62,  231,  797,    0],\n",
      "        [   4,    1,    8,   66,   62,  473,    0],\n",
      "        [  22,    1,   36,   68,  129,    1,    0],\n",
      "        [  35,   14,   74,   53,    8,  146,    0],\n",
      "        [   4,   33,  699,   13, 1266,    8,    0],\n",
      "        [   4,   33,  247,    8,   59,  247,    0],\n",
      "        [   1,    1,  404,   13,   34,   58,    0],\n",
      "        [  50,    1,   12,    7,  670,  791,    0],\n",
      "        [  43,   10,    8,    1, 1208,   17,    0],\n",
      "        [   4,  856,   23,    4,   15,  187,    0],\n",
      "        [   4,   15,    1,    8,  107,  162,    0],\n",
      "        [   6,  173,   37,   34,    1,    1,    0],\n",
      "        [  50,  763,  945,   12,    7,  431,    0],\n",
      "        [  81,   36,    1, 1017, 1471,    1,    0],\n",
      "        [   4,   47,  320,    8,   67,   87,    0],\n",
      "        [  20,   75, 1176,    1,    9,  718,    0],\n",
      "        [   4,   66,   72,  216,  594, 1055,    0],\n",
      "        [   4,   33,    1,    7,    1,  112,    0],\n",
      "        [  29,   91,   10,   16,   17,  195,    0],\n",
      "        [ 103,  345,    1,    9,  279,  611,    0],\n",
      "        [ 218,    8,  375,    6,   14,  317,    0],\n",
      "        [   4,  246,   23,   67,    5,    8,    0],\n",
      "        [   4,    1,   17,    4,   33,    1,    0],\n",
      "        [   1,    9, 1197,   61,  214,   17,    0],\n",
      "        [  24,   19,    9,  132,    5,  430,    0],\n",
      "        [   4,   41,    5,   48,    7,    1,    0],\n",
      "        [   4,   33,  366,    4,  117,  917,    0],\n",
      "        [   6,   40,   10,  108,   23,  487,    0],\n",
      "        [  24,   59,   26,  706,   36,    8,    0],\n",
      "        [  20,   11,    9,  279,  978,    1,    0],\n",
      "        [   6,   56,  116,  108,    5, 1265,    0],\n",
      "        [   4,   33,  786,   17,    8,  753,    0],\n",
      "        [  50,    1,  225,   73,    7,    1,    0],\n",
      "        [ 601,    6,   69,  100,   95,  165,   28],\n",
      "        [  20,   11, 1451,    5,  685,   34,    1],\n",
      "        [   4,  519,   44,    6,    1,   73,   17],\n",
      "        [  50,   11,    9,    1,   13,   31,    1],\n",
      "        [ 533,    1,   11,  110,    1,    5,   21],\n",
      "        [  80,    1,   11,    1,   18,    1,  296],\n",
      "        [   4,   49,   30,  754,    5,   52,   87],\n",
      "        [   4,  149,    1,   12,  204,  171,  662],\n",
      "        [  24,   48,    4,   40,   10,  775,   23],\n",
      "        [   4,  265,   19,   72,  187,   45,    6],\n",
      "        [  29,   59,   90,    5,  108,    9,  528],\n",
      "        [   4,   86,   53,    5,  180,   38,  793],\n",
      "        [ 238,   69,  139,    1,    1,    7,    1],\n",
      "        [   6,  277,   53,    9,   68,  414,  415],\n",
      "        [   6,   92,   10,   70,    7,  226,    1],\n",
      "        [   4,  262,    4,   92,   98,   38,    8],\n",
      "        [  29,    1,   54,  830,   13,  137,  390],\n",
      "        [ 892,    7, 1392,    7,    1,   15,    1],\n",
      "        [   6,  104,   28,   17,   30,   15,    1],\n",
      "        [   4,   91,  489,  980,    9,  237, 1252],\n",
      "        [   4,   16,   10,   49,    4,   41,   17],\n",
      "        [   4,   33,  109, 1387,    5,   70,  420],\n",
      "        [   6,  437,   28,   70,  154,   54,    1],\n",
      "        [   6,    1,   12,   84,  164,   17,  162],\n",
      "        [   4,   16,   10,   19,   60,    7,    1],\n",
      "        [ 148,   16,   10,    8,  920,   46,  634],\n",
      "        [   4,   16,   10,   19,  147,    5,    1],\n",
      "        [  81,  174,   19,    1,   21,   13,    1],\n",
      "        [   4,   33,   90,    5,  684,   32,  776],\n",
      "        [  80,  638,   11,    1,   21,    9,    1],\n",
      "        [  20,   56,   72,    1,   18,  125,  254],\n",
      "        [   6,   15, 1202,    1,   37,    7,  666],\n",
      "        [   4,   19,  116,  358,  120,   23,  377],\n",
      "        [ 199,   14,    7,  830,   13,   31,  968],\n",
      "        [   1,    1,   14,   11,    9,    1,    1],\n",
      "        [  24,   66,  117,    5,  593,   46,  241],\n",
      "        [  89,   11,  116,  296,   12,  495,    1]])\n",
      "Target sequences:\n",
      "tensor([   5,   37,   28, 1047,  230,   75,    4,    0,    0,    0,    0])\n",
      "tensor([[  5,  34, 368,  ...,   0,   0,   0],\n",
      "        [  5,  89,  80,  ...,   0,   0,   0],\n",
      "        [  5,  37,  28,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   4,   0],\n",
      "        [  6,  41,   1,  ...,   0,   0,   0],\n",
      "        [  7,   1,  20,  ...,   0,   0,   0]])\n",
      "Batch 3:\n",
      "Source sequences:\n",
      "tensor([81, 36, 68,  1,  0])\n",
      "tensor([[ 153,   14,   25,  829,    0],\n",
      "        [   4,   33,   18,   17,    0],\n",
      "        [   4,   15,   96,  679,    0],\n",
      "        [  81,   36,   68,    1,    0],\n",
      "        [  35,   14,  110,    1,    0],\n",
      "        [   1,   87,  129,    1,    0],\n",
      "        [   4,   15,    1,    1,    0],\n",
      "        [   1,   11,    1,    8,    0],\n",
      "        [   4,   33,  389,  161,    0],\n",
      "        [ 175,   14,    7,  284,    0],\n",
      "        [   4,   33,   26,    1,    0],\n",
      "        [  24,    1,   32,  831,    0],\n",
      "        [  55,   14,   46,    1,    0],\n",
      "        [   4,  131,  125, 1388,    0],\n",
      "        [  81,   63,   26,    1,    0],\n",
      "        [ 150,  713,    1,   42,    0],\n",
      "        [   6,  413,    5,    1,    0],\n",
      "        [ 940,    1,   42, 1324,    0],\n",
      "        [  24,   63,  109,  279,    0],\n",
      "        [  80,  903, 1026,    1,    0],\n",
      "        [   6,    1,    5,  730,    0],\n",
      "        [  22,    1,   14, 1142,    0],\n",
      "        [   6,   11,   68,    1,    0],\n",
      "        [   6,    1,   34,    1,    0],\n",
      "        [   4,  250,   23,  112,    0],\n",
      "        [   4,   96,    1,    6,    0],\n",
      "        [   1,   46,  471,    6,    0],\n",
      "        [   4,   47,    1,    8,    0],\n",
      "        [   1,    1,   38,    1,    0],\n",
      "        [  24,   19,  116,    1,    0],\n",
      "        [ 806,   23,   12,  258,    0],\n",
      "        [   1, 1128,  368,    6,    0],\n",
      "        [  24,  174,   25,    1,    0],\n",
      "        [ 828,    4,   33,  529,    0],\n",
      "        [ 153,   14,  499,   57,    0],\n",
      "        [  20,   15,  644,   87,    0],\n",
      "        [1151,    4,   33,  171,   57],\n",
      "        [   4,  141,    8,  107,  162],\n",
      "        [   1,   11,    9,  914,    1],\n",
      "        [   4,   19,   32,  518,    1],\n",
      "        [  29,    1,    1,  423,  466],\n",
      "        [   4,   19,   99,   18,    8],\n",
      "        [ 150,  205,   15,    9,    1],\n",
      "        [  55,  640,  156,   16,   17],\n",
      "        [ 140,    8,  280,   37,    1],\n",
      "        [  20,  109,  640,   21,  735],\n",
      "        [ 833,   65,  131,  128, 1283],\n",
      "        [   4,   33,  420,   45,    6],\n",
      "        [ 541,  156,    1,   34,    1],\n",
      "        [  22,    1,    1,   34,    1],\n",
      "        [   6,   44,   36,    8,  184],\n",
      "        [  24,   86,  135,   52,  111],\n",
      "        [   6,   40,   10,  399,    1],\n",
      "        [   4,   49,   65,   91,  401],\n",
      "        [  29,   47,   16,   31,  286],\n",
      "        [   6, 1488,    5,  100,   95],\n",
      "        [   4,   53,  297,   38,    8],\n",
      "        [  55,  106,  455,    1,  994],\n",
      "        [   1, 1128,  368,   32,    1],\n",
      "        [  22,    1,   15,  882,    1],\n",
      "        [  81,  108,    5,  250,  492],\n",
      "        [   6,   40,   10,   70,  513],\n",
      "        [ 565,    9,  393,  159,  127],\n",
      "        [   1,    1,   18,    9,  441],\n",
      "        [  35,   14,   26,   45,   17],\n",
      "        [  20,   15,  257,  538,  563],\n",
      "        [ 102,  622,   11,   46,  343],\n",
      "        [   6,  536,    7,  151,  226],\n",
      "        [  29,   66,  252,  144,  308],\n",
      "        [  20,  356,  255, 1477, 1194],\n",
      "        [ 103,  870,   11,    1,  203],\n",
      "        [   4,   15,    9,  315,  235],\n",
      "        [  50,   14,    9,    1,   76],\n",
      "        [   4,   19,    5,    1,   23],\n",
      "        [  50,  275,    9,    1,    1],\n",
      "        [ 987,   61,  267,   68,  818],\n",
      "        [   1,   46,  126,   12,  354],\n",
      "        [  20,  510,    1,   32,  880],\n",
      "        [  24,   47,   19,    5,   52],\n",
      "        [   4,  865,    4,   15,    1],\n",
      "        [   1,   11,    9,   83,    1],\n",
      "        [  35,   15,   10,    9,    1],\n",
      "        [   1,   23,   87,   26,   57],\n",
      "        [   4,   15,  392,   84,  616],\n",
      "        [   6,   11,   10,   32,  311],\n",
      "        [   6, 1454,    5,   34,    1],\n",
      "        [  50,    1,   38,    7,  145],\n",
      "        [  20,   14,   83,   39,  978],\n",
      "        [   4,  190,  169,    5,    1],\n",
      "        [1087,    8,  392,  107,  162],\n",
      "        [  20,   11,  819,   45, 1421],\n",
      "        [   6,   11,    9,    1,    1],\n",
      "        [   4,  519,   44,   17,   11],\n",
      "        [  22,    1,  411,    5,    1],\n",
      "        [ 177,  743,   67,    7,  907],\n",
      "        [  22,  276,    1,  538,  307],\n",
      "        [   6,  353,    9,    1,    1],\n",
      "        [ 274,    8,  259,   38,   21],\n",
      "        [  43,   10,   25,   53,   17],\n",
      "        [  35,   14,    9,  315,    1],\n",
      "        [  35,   15,   74,    9,    1],\n",
      "        [  35,   14,   74,    9, 1008],\n",
      "        [ 153,   14,    1,    9,  681],\n",
      "        [   1,   27, 1109,    5,    6],\n",
      "        [  29,   63,    9,  964,  854],\n",
      "        [   6,  397,    4,   53,   42],\n",
      "        [   6,  660,  119,    5,  260],\n",
      "        [   6,  382,    9,  237,  392],\n",
      "        [  24,   47,   25,  373,  492],\n",
      "        [  29,  265,   51,  134,  401],\n",
      "        [ 148,   11,   30,   94,    1],\n",
      "        [   4,  228,   45,   46,  240],\n",
      "        [  24,    1,  135,  101,   17],\n",
      "        [1362, 1197,   61,  375,   17],\n",
      "        [ 238,   69,   46,  223, 1095],\n",
      "        [  50,  157,  844, 1507,  639],\n",
      "        [  22,  426,  340,    5, 1293],\n",
      "        [   6,   11,    1,   32,    1],\n",
      "        [1121,  381,    1,   12,    1],\n",
      "        [  29,   63,   10, 1373,    1],\n",
      "        [ 533,    1,   14,   37,    1],\n",
      "        [   4,   47,   96,    1,  283],\n",
      "        [   4,  272,   13,    1,   67],\n",
      "        [  50,  277,    5,   25,  247],\n",
      "        [  43,   10,  246,   21,  195],\n",
      "        [   4,   66,   96, 1482,    6],\n",
      "        [   4,  275,   42,    7,  133],\n",
      "        [  24,   86,  135,  121,   31]])\n",
      "Target sequences:\n",
      "tensor([60, 52,  1,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "tensor([[133,   1,   4,  ...,   0,   0,   0],\n",
      "        [  5,  82,  35,  ...,   0,   0,   0],\n",
      "        [  5,  89,  80,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  5,  89,  80,  ...,   0,   0,   0],\n",
      "        [  5,   9, 196,  ...,   0,   0,   0],\n",
      "        [  6,  73, 168,  ...,   0,   0,   0]])\n",
      "Batch 4:\n",
      "Source sequences:\n",
      "tensor([457, 287,  44, 321, 455,   4, 580,   5,  52,   0,   0])\n",
      "tensor([[  1,   7, 182,  ...,   1,   0,   0],\n",
      "        [ 20, 179,   1,  ..., 633,   0,   0],\n",
      "        [  4, 118,   8,  ...,   6,   0,   0],\n",
      "        ...,\n",
      "        [ 22,   1,  92,  ...,  23,  15,   1],\n",
      "        [  1,  71,  27,  ...,  13, 805, 576],\n",
      "        [ 35,  14,  72,  ...,   5, 604, 168]])\n",
      "Target sequences:\n",
      "tensor([ 1, 71, 26, 20, 21,  5,  1, 37,  4,  0,  0,  0,  0,  0])\n",
      "tensor([[   1,   21,   15,  ...,    0,    0,    0],\n",
      "        [  92,   53, 1337,  ...,    0,    0,    0],\n",
      "        [  27,   48,    6,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,   36,    1,  ...,    0,    0,    0],\n",
      "        [  37,   53,  158,  ...,    0,    0,    0],\n",
      "        [   1,  626,  107,  ...,    4,    0,    0]])\n",
      "Batch 5:\n",
      "Source sequences:\n",
      "tensor([  1,  58,  17,   4,  85,   8,   4,  49,  13,  32, 223,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0])\n",
      "tensor([[274,   8,  27,  ...,   0,   0,   0],\n",
      "        [  4,  64,  10,  ...,   0,   0,   0],\n",
      "        [  6,  11,  57,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  4,  48,  23,  ...,   0,   0,   0],\n",
      "        [ 29,   1,   1,  ...,   0,   0,   0],\n",
      "        [408, 238,  77,  ..., 227,  21, 409]])\n",
      "Target sequences:\n",
      "tensor([  1, 148,   5,  78,   6,  21,   5,  48,  49, 313,   5,   4,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0])\n",
      "tensor([[   6,   43,  409,  ...,    0,    0,    0],\n",
      "        [  27,   55,   74,  ...,    0,    0,    0],\n",
      "        [  25,   23,   51,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  27,   46,   98,  ...,    0,    0,    0],\n",
      "        [  29,   17, 1068,  ...,    0,    0,    0],\n",
      "        [ 233,   42,   72,  ...,  225,    4,  233]])\n",
      "Batch 6:\n",
      "Source sequences:\n",
      "tensor([221, 132,  61, 267,  12, 125, 167,   0])\n",
      "tensor([[  1, 513,  30,  ...,  84, 166,   0],\n",
      "        [ 24, 122,  21,  ...,   1,  67,   0],\n",
      "        [  4,  40,  23,  ...,  10,   4,   0],\n",
      "        ...,\n",
      "        [  4,  16,  10,  ..., 222,  45,  54],\n",
      "        [ 22, 476, 854,  ...,   7, 242,   1],\n",
      "        [ 79, 256, 155,  ..., 219,  39,   8]])\n",
      "Target sequences:\n",
      "tensor([ 52,  61,  35,  36,  88,  53,  30, 121, 107,   4,   0,   0])\n",
      "tensor([[  1, 474,  21,  ...,   0,   0,   0],\n",
      "        [  6,  24,  22,  ...,   0,   0,   0],\n",
      "        [  5,   9,  24,  ...,   7,  14,   0],\n",
      "        ...,\n",
      "        [  5,   7,  46,  ...,   0,   0,   0],\n",
      "        [  1,   1, 256,  ...,   0,   0,   0],\n",
      "        [151, 184, 930,  ...,   0,   0,   0]])\n",
      "Batch 7:\n",
      "Source sequences:\n",
      "tensor([   6,    1, 1398,    0])\n",
      "tensor([[   6,    1,    0,    0],\n",
      "        [1365, 1288,    0,    0],\n",
      "        [   1,  918,    0,    0],\n",
      "        [   1,  767,    0,    0],\n",
      "        [  20,  478,    0,    0],\n",
      "        [   6,    1,   21,    0],\n",
      "        [  81,  574,  239,    0],\n",
      "        [   6,    1, 1398,    0],\n",
      "        [   4,  149,  297,    0],\n",
      "        [  43,   10,  318,    0],\n",
      "        [  43,   23,  195,    0],\n",
      "        [  35,   15,  534,    0],\n",
      "        [  29,   59,  224,    0],\n",
      "        [ 140,    8,    1,    0],\n",
      "        [   6,  179,  383,    0],\n",
      "        [   6,    1,  325,    0],\n",
      "        [   1,   23,  170,    0],\n",
      "        [   4,  117,   23,    0],\n",
      "        [   6,  998,  939,    0],\n",
      "        [   6,   14, 1011,    0],\n",
      "        [   6,   15,  747,    0],\n",
      "        [   4,   41,    1,    0],\n",
      "        [   6,  381, 1252,    0],\n",
      "        [  28,   11,    1,    0],\n",
      "        [   6,    1,   99,    0],\n",
      "        [   4, 1138,  207,    0],\n",
      "        [   6,   11,    1,    0],\n",
      "        [   6,  344,    1,    0],\n",
      "        [  79,   14,    1,    0],\n",
      "        [  35,   15, 1508,    0],\n",
      "        [   6,   15,  278,    0],\n",
      "        [   1,    1,    1,    0],\n",
      "        [  79,   15,  534,    0],\n",
      "        [ 115,   17,  270,    0],\n",
      "        [  35,   14,    1,    0],\n",
      "        [  29,   36,    1,    0],\n",
      "        [   6,   74,    1,    0],\n",
      "        [   4,   15,  513,    0],\n",
      "        [  79,    1,  452,    0],\n",
      "        [   6,    1,   28,    0],\n",
      "        [   1,  920,   67,    0],\n",
      "        [   6,    1,    1,    0],\n",
      "        [  79,   14,    1,    0],\n",
      "        [   4,   33,    1,    0],\n",
      "        [  24,   59,  775,    0],\n",
      "        [  35,   14,    1,    0],\n",
      "        [  79,   14, 1305,    0],\n",
      "        [   6,  351,  426,    0],\n",
      "        [   6,   11,    1,    0],\n",
      "        [ 140,    8,    1,    0],\n",
      "        [1365,   17,  850,    0],\n",
      "        [  50,    1,   42,    0],\n",
      "        [   4,   53,    1,    0],\n",
      "        [   6,   11,    1,    0],\n",
      "        [   6,  277, 1496,    0],\n",
      "        [  29,  174,  401,    0],\n",
      "        [ 449,  418,  204,    0],\n",
      "        [  80,   11,    1,    0],\n",
      "        [  79,   14, 1059, 1214],\n",
      "        [   1,   91,   78,    6],\n",
      "        [  24,    1,    7, 1066],\n",
      "        [  81,  611,   38,    1],\n",
      "        [ 199,  149,    4,    1],\n",
      "        [   6,  231,   34, 1157],\n",
      "        [   4,  149,  502,    1],\n",
      "        [  29,   41,    5,  100],\n",
      "        [   1,  329,   85,   95],\n",
      "        [  24,   59,    9,    1],\n",
      "        [  55,   14,    7,  611],\n",
      "        [  29,   59,   26,  224],\n",
      "        [   1,   11,   10,   87],\n",
      "        [   1,    1,   18,    1],\n",
      "        [  81,   92,   25,  972],\n",
      "        [   1,   69,    1,  210],\n",
      "        [ 115,   32,    1,  891],\n",
      "        [  24,  198,    1,  339],\n",
      "        [  29,   66,    1,    6],\n",
      "        [  89,   14,  116,  480],\n",
      "        [ 175,   14,    7,  151],\n",
      "        [   6,  545,   12,    1],\n",
      "        [ 140,    8,    1,   99],\n",
      "        [   6,    1,   46,    1],\n",
      "        [   1,   74,    9,  441],\n",
      "        [   1,    1,    1,    1],\n",
      "        [ 153,   14,   52,    1],\n",
      "        [ 565,    9,    1,  865],\n",
      "        [   4,   33,    1,   99],\n",
      "        [   6,   11,    9,    1],\n",
      "        [  50,  918, 1233,  818],\n",
      "        [ 148,   11,    6,   87],\n",
      "        [   4,    1,    6,   76],\n",
      "        [  79,   14,  110,  336],\n",
      "        [ 153,   21,  440,  248],\n",
      "        [ 175,   11,   32,  311],\n",
      "        [   4,   41,  385,  463],\n",
      "        [  24,  108,    5,  246],\n",
      "        [ 148,   36,   65,    1],\n",
      "        [   6,  536,   34,    1],\n",
      "        [  20,   11,    9,    1],\n",
      "        [1270,  170,    7,    1],\n",
      "        [   6,  532,   56,    1],\n",
      "        [ 221,  151,  179,   73],\n",
      "        [   4,  206, 1493,   42],\n",
      "        [   6,   11,  116,    1],\n",
      "        [  29,   63,   10,    1],\n",
      "        [  79,   11,   34,  151],\n",
      "        [ 218,    6,  146,  181],\n",
      "        [  20,    1,    5,   21],\n",
      "        [  29,   59,  805,  576],\n",
      "        [   1,  147,  994,  201],\n",
      "        [ 153,   14,   70,  261],\n",
      "        [ 148,   36,    8,  676],\n",
      "        [  20,   11,    9,    1],\n",
      "        [  20,   14,   94,  452],\n",
      "        [  35,  178,   10,  310],\n",
      "        [  22,    1,  231,    1],\n",
      "        [  20,   11,    9,    1],\n",
      "        [  24,   91,   10,    1],\n",
      "        [  35,   15,   10,  477],\n",
      "        [   1,    5,   46,    1],\n",
      "        [   4,   47,  531,  283],\n",
      "        [ 601,    8,   63,  187],\n",
      "        [   4,   47,   52,  196],\n",
      "        [ 766,   61,  100,   21],\n",
      "        [  55,   40,    8,    1],\n",
      "        [ 919, 1320,    1,    1],\n",
      "        [   4,    1,    8,    6],\n",
      "        [   4,   74,  192,    1]])\n",
      "Target sequences:\n",
      "tensor([  8, 182, 499,   0,   0,   0,   0,   0])\n",
      "tensor([[  8, 237,   4,  ...,   0,   0,   0],\n",
      "        [314, 240,   0,  ...,   0,   0,   0],\n",
      "        [269, 459,   0,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [ 61,  40, 380,  ...,  22, 726,   0],\n",
      "        [  5,   9, 837,  ...,  21,   8,   4],\n",
      "        [  5,  77,  32,  ...,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def get_iterator(data, batch_size, source_vocab, target_vocab, device):\n",
    "    src_sents = [x[0] for x in data]\n",
    "    trg_sents = [x[1] for x in data]\n",
    "\n",
    "    # Sort the sentences by length for efficiency\n",
    "    sorted_indices = sorted(range(len(src_sents)), key=lambda i: len(src_sents[i]))\n",
    "\n",
    "    # Split the data into batches\n",
    "    batches = []\n",
    "    for i in range(0, len(src_sents[:batch_size*128]), batch_size):\n",
    "        indices = sorted_indices[i:i+batch_size]\n",
    "        src_batch = [src_sents[j] for j in indices]\n",
    "        trg_batch = [trg_sents[j] for j in indices]\n",
    "        batch = {\"src\": src_batch, \"trg\": trg_batch}\n",
    "        batches.append(batch)\n",
    "\n",
    "    # Shuffle the batches\n",
    "    random.shuffle(batches)\n",
    "\n",
    "    # Iterate over the batches\n",
    "    for batch in batches:\n",
    "        # Convert the sentences to sequences of indices\n",
    "        src_seqs = [torch.LongTensor([source_vocab[token] if token in source_vocab else source_vocab['<unk>'] for token in sent]) for sent in batch['src']]\n",
    "        trg_seqs = [torch.LongTensor([target_vocab[token] if token in target_vocab else target_vocab['<unk>'] for token in sent]) for sent in batch['trg']]\n",
    "\n",
    "        # Pad the sequences\n",
    "        src_seqs = torch.nn.utils.rnn.pad_sequence(src_seqs, batch_first=True, padding_value=source_vocab['<pad>']).to(device)\n",
    "        trg_seqs = torch.nn.utils.rnn.pad_sequence(trg_seqs, batch_first=True, padding_value=target_vocab['<pad>']).to(device)\n",
    "\n",
    "        # Return the batch\n",
    "        yield {\"src\": src_seqs, \"trg\": trg_seqs}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_batches = get_iterator(train_examples, BATCH_SIZE, source_vocab, target_vocab, device)\n",
    "valid_batches = get_iterator(val_examples, BATCH_SIZE, source_vocab, target_vocab, device)\n",
    "test_batches = get_iterator(test_examples, BATCH_SIZE, source_vocab, target_vocab, device)\n",
    "\n",
    "for i, batch in enumerate (test_batches):\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(\"Source sequences:\")\n",
    "    print(batch[\"src\"][i])\n",
    "    print(batch[\"src\"])\n",
    "    print(\"Target sequences:\")\n",
    "    print(batch[\"trg\"][i])\n",
    "    print(batch[\"trg\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128, 1024]) torch.Size([128, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# adjustable parameters\n",
    "INPUT_DIM = len(source_vocab)\n",
    "OUTPUT_DIM = len(target_vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "N_LAYERS = 1\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, n_layers, dropout=dropout,\n",
    "                          bidirectional=True)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "\n",
    "    def forward(self, src_batch):\n",
    "        # src [sent len, batch size]\n",
    "\n",
    "        # [sent len, batch size, emb dim]\n",
    "        embedded = self.embedding(src_batch)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs -> [sent len, batch size, hidden dim * n directions]\n",
    "        # hidden -> [n layers * n directions, batch size, hidden dim]\n",
    "\n",
    "        # initial decoder hidden is final hidden state of the forwards and\n",
    "        # backwards encoder RNNs fed through a linear layer\n",
    "        concated = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        hidden = torch.tanh(self.fc(concated))\n",
    "        return outputs, hidden\n",
    "\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
    "outputs, hidden = encoder(batch[\"src\"])\n",
    "outputs = outputs.permute(1, 0, 2)\n",
    "hidden = hidden.repeat(32, 1)\n",
    "# transpose the outputs tensor to have batch size as the first dimension\n",
    "print(outputs.shape, hidden.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        # enc_hid_dim multiply by 2 due to bidirectional\n",
    "        self.fc1 = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
    "        self.fc2 = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        \n",
    "        # repeat encoder hidden state src_len times [batch size, sent len, dec hid dim]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        # reshape/permute the encoder output, so that the batch size comes first\n",
    "        # [batch size, sent len, enc hid dim * 2], times 2 because of bidirectional\n",
    "        outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        # the attention mechanism receives a concatenation of the hidden state\n",
    "        # and the encoder output\n",
    "        concat = torch.cat((hidden, outputs), dim=2)\n",
    "        \n",
    "        # fully connected layer and softmax layer to compute the attention weight\n",
    "        # [batch size, sent len, dec hid dim]\n",
    "        energy = torch.tanh(self.fc1(concat))\n",
    "        # attention weight should be of [batch size, sent len]\n",
    "        attention = self.fc2(energy).squeeze(dim=2)  \n",
    "        attention_weight = torch.softmax(attention, dim=1)\n",
    "        return attention_weight\n",
    "\n",
    "    \n",
    "attention = Attention(ENC_HID_DIM, DEC_HID_DIM).to(device)\n",
    "attention_weight = attention(outputs, hidden)\n",
    "attention_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded shape: torch.Size([1, 8, 256])\n",
      "context shape: torch.Size([1, 128, 1024])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 8 but got size 128 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m prediction, hidden\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m     45\u001b[0m decoder \u001b[39m=\u001b[39m Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attention)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 46\u001b[0m prediction, decoder_hidden \u001b[39m=\u001b[39m decoder(batch[\u001b[39m\"\u001b[39;49m\u001b[39mtrg\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m], outputs, hidden)\n\u001b[0;32m     48\u001b[0m \u001b[39m# notice the decoder_hidden's shape should match the shape that's generated by\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m# the encoder\u001b[39;00m\n\u001b[0;32m     50\u001b[0m prediction\u001b[39m.\u001b[39mshape, decoder_hidden\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[111], line 37\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, trg, encoder_outputs, hidden)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39membedded shape:\u001b[39m\u001b[39m'\u001b[39m, embedded\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     36\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcontext shape:\u001b[39m\u001b[39m'\u001b[39m, context\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 37\u001b[0m rnn_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((embedded, context), dim\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     40\u001b[0m outputs, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(rnn_input, hidden\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[0;32m     41\u001b[0m prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(outputs\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 8 but got size 128 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers,\n",
    "                 dropout, attention):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(enc_hid_dim * 2 + emb_dim, dec_hid_dim, n_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(dec_hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, trg, encoder_outputs, hidden):\n",
    "        # trg [batch size]\n",
    "        # outputs [src sen len, batch size, enc hid dim * 2], times 2 due to bidirectional\n",
    "        # hidden [batch size, dec hid dim]\n",
    "\n",
    "        # [batch size, 1, sent len] \n",
    "        attention = self.attention(encoder_outputs, hidden).unsqueeze(1)\n",
    "\n",
    "        # [batch size, sent len, enc hid dim * 2]\n",
    "        outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        # [1, batch size, enc hid dim * 2]\n",
    "        context = torch.bmm(attention, outputs).permute(1, 0, 2)\n",
    "\n",
    "        # input sentence -> embedding\n",
    "        # [1, batch size, emb dim]\n",
    "        embedded = self.embedding(trg.unsqueeze(0))\n",
    "        print('embedded shape:', embedded.shape)\n",
    "        print('context shape:', context.shape)\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "        \n",
    "\n",
    "        outputs, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        prediction = self.linear(outputs.squeeze(0))\n",
    "        return prediction, hidden.squeeze(0)\n",
    "\n",
    "\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attention).to(device)\n",
    "prediction, decoder_hidden = decoder(batch[\"trg\"][0], outputs, hidden)\n",
    "\n",
    "# notice the decoder_hidden's shape should match the shape that's generated by\n",
    "# the encoder\n",
    "prediction.shape, decoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(1535, 256)\n",
       "    (rnn): GRU(256, 512, dropout=0.5, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (fc1): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(1359, 256)\n",
       "    (rnn): GRU(1280, 512, dropout=0.5)\n",
       "    (linear): Linear(in_features=512, out_features=1359, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src_batch, trg_batch, teacher_forcing_ratio=0.5):\n",
    "        max_len, batch_size = trg_batch.shape\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # encoder_outputs : all hidden states of the input sequence (forward and backward)\n",
    "        # hidden : final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src_batch)\n",
    "\n",
    "        trg = trg_batch[0]\n",
    "        for i in range(1, max_len):\n",
    "            prediction, hidden = self.decoder(trg, encoder_outputs, hidden)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                trg = trg_batch[i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "attention = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attention)\n",
    "seq2seq = Seq2Seq(encoder, decoder, device).to(device)\n",
    "seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 1024])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in test_batches:\n",
    "    src = batch[\"src\"]\n",
    "    trg = batch[\"trg\"]\n",
    "    outputs = seq2seq(src, trg)\n",
    "    # do something with the outputs\n",
    "\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,871,311 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(seq2seq):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq2seq.parameters())\n",
    "\n",
    "# ignore the padding index when calculating the loss\n",
    "PAD_IDX = target_vocab['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\16262\\AppData\\Local\\Temp\\ipykernel_14776\\3771389847.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  inputs = np.array(inputs)\n",
      "C:\\Users\\16262\\AppData\\Local\\Temp\\ipykernel_14776\\3771389847.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  targets = np.array(targets)\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m     53\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 54\u001b[0m     train_loss \u001b[39m=\u001b[39m train(seq2seq, train_iterator, optimizer, criterion)\n\u001b[0;32m     55\u001b[0m     valid_loss \u001b[39m=\u001b[39m evaluate(seq2seq, valid_iterator, criterion)\n\u001b[0;32m     56\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[110], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(seq2seq, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(iterator):\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m     outputs \u001b[39m=\u001b[39m seq2seq(batch\u001b[39m.\u001b[39;49msrc, batch\u001b[39m.\u001b[39mtrg)\n\u001b[0;32m     12\u001b[0m     \u001b[39m# the loss function only works on 2d inputs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39m# and 1d targets we need to flatten each of them\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     outputs_flatten \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, outputs\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'src'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "def train(seq2seq, iterator, optimizer, criterion):\n",
    "    seq2seq.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = seq2seq(batch.src, batch.trg)\n",
    "\n",
    "        # the loss function only works on 2d inputs\n",
    "        # and 1d targets we need to flatten each of them\n",
    "        outputs_flatten = outputs[1:].view(-1, outputs.shape[-1])\n",
    "        trg_flatten = batch.trg[1:].view(-1)\n",
    "        loss = criterion(outputs_flatten, trg_flatten)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(seq2seq, iterator, criterion):\n",
    "    seq2seq.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(iterator):\n",
    "            # turn off teacher forcing\n",
    "            outputs = seq2seq(batch.src, batch.trg, teacher_forcing_ratio=0) \n",
    "\n",
    "            # trg = [trg sent len, batch size]\n",
    "            # output = [trg sent len, batch size, output dim]\n",
    "            outputs_flatten = outputs[1:].view(-1, outputs.shape[-1])\n",
    "            trg_flatten = batch.trg[1:].view(-1)\n",
    "            loss = criterion(outputs_flatten, trg_flatten)\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 30\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(seq2seq, train_iterator, optimizer, criterion)\n",
    "    valid_loss = evaluate(seq2seq, valid_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(seq2seq.state_dict(), 'tut2-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
